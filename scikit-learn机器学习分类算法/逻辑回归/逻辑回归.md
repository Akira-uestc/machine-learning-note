##### 逻辑回归是一个非常经典的算法，用于解决分类问题的机器学习方法，用于估计某种事物的可能性，其有着简单、可并行化、可解释强的特点。逻辑回归虽然被称为回归，实际上是分类模型，并常用于二分类。

##### 逻辑回归的本质是假设数据服从这个分布，然后使用极大似然估计做参数的估计。其分布是由位置和尺度参数定义的连续分布。分布的形状与正态分布的形状相似，但是其分布的尾部更长，所以可以使用逻辑分布来建模比正态分布具有更长尾部和更高波峰的数据分布。
        1.找到分类边界（曲线）
        2.拟合曲线+Sigmoid压缩函数分类
##### sigmoid函数
        g(z) = 1/(1+exp(-z))
        
        一般选择0.5作为阈值，特定的情况可以选择不同阈值（对正例的判别准确性要求高，可以选择更大的阈值，对正例的召回要求高，可以选择更小的阈值）。
##### 决策边界
        决策边界，也称为决策面，是用于在N维空间，将不同类别样本分开的平面或曲面。决策边界就是一个方程
        
        决策边界是假设函数的属性，由参数决定，不是由数据集的特征决定
##### 代价函数
        代价函数（损失函数）就是能够衡量模型预测值与真实值之间差异的函数，如果有多个样本，则可以将所有代价函数的值求平均或者求和
        
#### 逻辑回归算法去除Sigmoid映射函数就是一个线性回归。也就是说，逻辑回归以线性回归为理论支持，并通过Sigmoid函数引入了非线性因素，可以轻松处理0/1分类问题
